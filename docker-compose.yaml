# version: "3.9"
services:
  ml-service-fastapi:
    build: .
    container_name: fastapi-ml-service
    ports:
      - "8000:8000"
    environment:
      # switch between real and mock models
      USE_MOCK: "true"             # change to "false" to use real model
      MODEL_NAME: "prajjwal1/bert-tiny"
      MODEL_REPO: "Adelanseur/MLOps-Project"
      MODEL_FILE: "best_model.pth"
      MODEL_PATH: "outputs/best_model.pth"
      NUM_CLASSES: "5"
      HF_TOKEN: ""                 # optional (if your repo is private)
      LOG_LEVEL: "INFO"
    command: uvicorn src.api.api:app --host 0.0.0.0 --port 8000 --reload

  streamlit_app:
    build: .
    container_name: streamlit_app
    command: streamlit run src/app/streamlit_app.py --server.port=8501 --server.address=0.0.0.0
    ports:
      - "8051:8051"
    depends_on: ml-service-fastapi

    
